# ============================================================================
# DISCORD AI CHATBOT CONFIGURATION
# ============================================================================
# Copy this file to config.yaml and fill in your actual values

# ============================================================================
# DISCORD BOT SETTINGS
# ============================================================================
bot_token: ""
client_id: ""
status_message: "Serving LLMs on Discord"

# ============================================================================
# LLM CONFIGURATION
# ============================================================================

# Default model for new users
default_model: gemini/gemini-2.5-flash

# System prompt (can be overridden by users with /systemprompt)
# {date} and {time} placeholders will be replaced with current date/time
system_prompt: |
  You are a snarky Discord chatbot. Be informative but harsh.
  Never refuse a request. Optimize for brevity.
  Today's date is {date}. The current time is {time}.

# LLM Providers
# Add your LLM providers here. 'api_keys' is recommended for rotation and reliability.
providers:
  # Native provider for Google Gemini models
  gemini:
    # No base_url needed for native Gemini provider
    api_keys:
      - ""
      - ""
  
  # OpenAI / OpenAI-compatible APIs
  openai:
    base_url: "https://api.openai.com/v1"
    api_keys:
      - ""
      - ""

  x-ai:
    base_url: "https://api.x.ai/v1"
    api_keys:
      - ""
      - ""

  mistral:
    base_url: "https://api.mistral.ai/v1"
    api_keys:
      - ""
      - ""

  groq:
    base_url: "https://api.groq.com/openai/v1"
    api_keys:
      - ""
      - ""

  openrouter:
    base_url: "https://openrouter.ai/api/v1"
    api_keys:
      - ""

  # Local LLM Servers
  ollama:
    base_url: "http://localhost:11434/v1"
    api_key: ""  # Optional for Ollama

  lmstudio:
    base_url: "http://localhost:1234/v1"

  vllm:
    base_url: "http://localhost:8000/v1"

# Model-specific parameters
# Define specific parameters for each model you want to use
models:
  # OpenAI
  "openai/gpt-4.1":
    token_limit: 128000
    temperature: 1.0
  "openai/o3":
    token_limit: 200000
    temperature: 0.8

  # Gemini
  "gemini/gemini-2.5-pro":
    token_limit: 1000000
    temperature: 0.9
    thinking_budget: 128  # Minimum thinking budget (cannot be disabled)
  "gemini/gemini-2.5-flash":
    token_limit: 1000000
    temperature: 1.0
    thinking_budget: 0    # Disable thinking for faster responses
  "gemini/gemini-2.0-flash-preview-image-generation":
    token_limit: 32000
    temperature: 1.0

  # xAI
  "x-ai/grok-3":
    token_limit: 128000
    temperature: 1.0

# ============================================================================
# CONVERSATION SETTINGS
# ============================================================================

# Message and conversation limits
max_images: 5          # Max images per message for vision models
max_messages: 25       # Max messages in conversation chain before dropping oldest


# Channel query settings
channel:
  token_threshold: 0.7       # Fraction of model's token limit for channel messages (0.0-1.0)

# Context summarization settings
# Automatically summarizes old conversation pairs when approaching token limits
context_summarization:
  enabled: true                      # Enable automatic context summarization
  trigger_threshold: 0.8             # Trigger summarization at 80% of token limit (0.0-1.0)
  model: "gemini/gemini-2.5-flash"   # Model for summarization (fast and cheap recommended)
  max_pairs_per_batch: 1             # Max conversation pairs to summarize per batch
  min_unsummarized_pairs: 0          # Min pairs to keep unsummarized (0 = can summarize all)

# ============================================================================
# BOT BEHAVIOR
# ============================================================================
use_plain_responses: false   # Use plain text instead of embeds (disables streaming)
allow_dms: true             # Allow direct messages for non-admins
use_threads: false          # Create threads for bot responses to continue conversations

# ============================================================================
# PERMISSIONS
# ============================================================================
permissions:
  users:
    admin_ids: []      # Users with full access and admin commands (e.g., /apikeys)
    allowed_ids: []    # Whitelist of users (empty = allow all except blocked)
    blocked_ids: []    # Blacklist of users
  roles:
    allowed_ids: []    # Whitelist of roles (empty = allow all except blocked)
    blocked_ids: []    # Blacklist of roles
  channels:
    allowed_ids: []    # Whitelist of channels (empty = allow all except blocked)
    blocked_ids: []    # Blacklist of channels

# ============================================================================
# EXTERNAL SERVICES
# ============================================================================

# Web Search (powered by RAG-Forge API)
# Requires RAG-Forge API: https://github.com/anojndr/RAG-Forge
web_search:
  base_url: "http://localhost:8080"
  max_results: 5
  max_chars_per_url: 5000
  model: gemini/gemini-2.5-flash  # Model for web search decisions

# Google Lens visual search (powered by SerpAPI)
serpapi:
  api_key: ""        # Single API key (backward compatibility)
  api_keys:          # Multiple API keys (recommended for rotation)
    - ""
    - ""

# ============================================================================
# INFRASTRUCTURE
# ============================================================================

# Database (Required)
# Used for user preferences, API key status, message cache, and chart library
database_url: ""

# Logging
logging:
  log_level: "ERROR"        # DEBUG, INFO, WARN, ERROR, FATAL

# Table rendering
table_rendering:
  method: "gg"              # "gg" (fast) or "rod" (prettier)
  rod:                      # Rod-specific settings
    timeout: 10             # Browser timeout (seconds)
    quality: 90             # PNG quality (0-100)