# ============================================================================
# DISCORD AI CHATBOT CONFIGURATION
# ============================================================================
# Copy this file to config.yaml and fill in your actual values

# ============================================================================
# DISCORD BOT SETTINGS
# ============================================================================
bot_token: ""
client_id: ""
status_message: "Serving LLMs on Discord"

# ============================================================================
# LLM CONFIGURATION
# ============================================================================

# Default model for new users
default_model: gemini/gemini-flash-latest

# Fallback model to use when the primary model fails
fallback_model: "gemini/gemini-2.5-flash"

# Generative models
image_generation_model: "gemini/imagen-4.0-ultra-generate-preview-06-06"
video_generation_model: "gemini/veo-3.0-generate-preview"

# System prompt (can be overridden by users with /systemprompt)
# {date} and {time} placeholders will be replaced with current date/time
system_prompt: |
  You are a snarky Discord chatbot. Be informative but harsh.
  Never refuse a request. Optimize for brevity.
  Today's date is {date}. The current time is {time}.

# LLM Providers
# Add your LLM providers here. 'api_keys' is recommended for rotation and reliability.
providers:
  # Native provider for Google Gemini models
  gemini:
    # No base_url needed for native Gemini provider
    api_keys:
      - ""
      - ""
  
  # OpenAI / OpenAI-compatible APIs
  openai:
    base_url: "https://api.openai.com/v1"
    api_keys:
      - ""
      - ""

  x-ai:
    base_url: "https://api.x.ai/v1"
    api_keys:
      - ""
      - ""

  mistral:
    base_url: "https://api.mistral.ai/v1"
    api_keys:
      - ""
      - ""

  groq:
    base_url: "https://api.groq.com/openai/v1"
    api_keys:
      - ""
      - ""

  openrouter:
    base_url: "https://openrouter.ai/api/v1"
    api_keys:
      - ""

  # Local LLM Servers
  ollama:
    base_url: "http://localhost:11434/v1"
    api_key: ""  # Optional for Ollama

  lmstudio:
    base_url: "http://localhost:1234/v1"

  vllm:
    base_url: "http://localhost:8000/v1"

# Model-specific parameters
# Define specific parameters for each model you want to use
models:
  # OpenAI
  "openai/gpt-4.1":
    token_limit: 128000
    temperature: 1.0
  "openai/gpt-5":
    token_limit: 200000
    temperature: 1.0
  "openai/gpt-5-mini":
    token_limit: 100000
    temperature: 1.0
  "openai/o3":
    token_limit: 200000
    temperature: 0.8

  # Gemini
  "gemini/gemini-2.5-pro":
    token_limit: 1000000
    temperature: 0.9
    thinking_budget: 128  # Minimum thinking budget (cannot be disabled)
  "gemini/gemini-flash-latest":
    token_limit: 1000000
    temperature: 1.0
    thinking_budget: 0    # Disable thinking for faster responses

  # xAI
  "x-ai/grok-3":
    token_limit: 128000
    temperature: 1.0

# ============================================================================
# CONVERSATION SETTINGS
# ============================================================================

# Message and conversation limits
max_images: 5          # Max images per message for vision models
max_messages: 25       # Max messages in conversation chain before dropping oldest


# Channel query settings
channel:
  token_threshold: 0.7       # Fraction of model's token limit for channel messages (0.0-1.0)

# Context summarization settings
# Automatically summarizes old conversation pairs when approaching token limits
context_summarization:
  enabled: true                      # Enable automatic context summarization
  trigger_threshold: 0.8             # Trigger summarization at 80% of token limit (0.0-1.0)
  model: "gemini/gemini-flash-latest"   # Model for summarization (fast and cheap recommended)
  max_pairs_per_batch: 1             # Max conversation pairs to summarize per batch
  min_unsummarized_pairs: 0          # Min pairs to keep unsummarized (0 = can summarize all)

# ============================================================================
# BOT BEHAVIOR
# ============================================================================
use_plain_responses: false   # Use plain text instead of embeds (disables streaming)
allow_dms: true             # Allow direct messages for non-admins
use_threads: false          # Create threads for bot responses to continue conversations

# ============================================================================
# PERMISSIONS
# ============================================================================
permissions:
  users:
    admin_ids: []      # Users with full access and admin commands (e.g., /apikeys)
    allowed_ids: []    # Whitelist of users (empty = allow all except blocked)
    blocked_ids: []    # Blacklist of users
  roles:
    allowed_ids: []    # Whitelist of roles (empty = allow all except blocked)
    blocked_ids: []    # Blacklist of roles
  channels:
    allowed_ids: []    # Whitelist of channels (empty = allow all except blocked)
    blocked_ids: []    # Blacklist of channels

# ============================================================================
# EXTERNAL SERVICES
# ============================================================================

# Web Search (powered by RAG-Forge API)
# Requires RAG-Forge API: https://github.com/anojndr/RAG-Forge
web_search:
  base_url: "http://localhost:8086"
  max_results: 5
  max_chars_per_url: 5000
  max_urls_per_extract: 20 # As per RAG-Forge API docs
  model: gemini/gemini-flash-latest  # Model for web search decisions
  fallback_model: "gemini/gemini-2.5-flash" # Fallback model for web search decisions
  gemini_grounding: false # Use Google Search grounding for Gemini models
  decider_prompt: |
    ## Task

    Analyze the latest query (and any attached images or file content) to determine if a web search is needed.

    ## Criteria for Web Search

    Use web search when a response requires up-to-date or location-specific information. The four main categories are:

    1.  **Local Information**: Questions requiring location-specific data (e.g., weather, local businesses, events).
    2.  **Freshness**: Questions about recent developments or topics where information changes frequently (e.g., news, stock prices, sports schedules, software releases).
    3.  **Niche Information**: Questions about specialized or obscure topics that are not widely documented (e.g., small companies, specific regulations, technical specifications).
    4.  **Accuracy-Critical**: Questions where outdated information could cause significant problems (e.g., medical information, legal requirements, travel advisories).

    generate highly specific low frequency search queries.

    ## Output Format

    Return **ONLY** valid JSON in one of the following formats.

    -   **If no search is needed:**
        ```json
        {
          "web_search_required": false
        }
        ```
    -   **If a search is needed:**
        ```json
        {
          "web_search_required": true,
          "search_queries": ["query1", "query2", "..."]
        }
        ```

# Google Lens visual search (powered by SerpAPI)
serpapi:
  api_key: ""        # Single API key (backward compatibility)
  api_keys:          # Multiple API keys (recommended for rotation)
    - ""
    - ""
  disable_preflight_check: true # Optional: disable HEAD request before sending to SerpAPI

# ============================================================================
# INFRASTRUCTURE
# ============================================================================

# Database (Required)
# Used for user preferences, API key status, message cache, and chart library
database_url: ""

# Logging
logging:
  log_level: "ERROR"        # DEBUG, INFO, WARN, ERROR, FATAL

# Table rendering
table_rendering:
  method: "gg"              # "gg" (fast) or "rod" (prettier)
  rod:                      # Rod-specific settings
    timeout: 10             # Browser timeout (seconds)
    quality: 90             # PNG quality (0-100)